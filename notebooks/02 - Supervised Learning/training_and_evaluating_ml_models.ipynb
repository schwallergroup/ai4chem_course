{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7b6d7b6-698e-4ea2-b8e9-bad6f279fcfe",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/schwallergroup/ai4chem_course/blob/scikit_learn/notebooks/02%20-%20Supervised%20Learning/training_and_evaluating_ml_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7ee09d-524b-4f90-ac5c-cc37187ba4c4",
   "metadata": {},
   "source": [
    "# Week 2 tutorial - AI 4 Chemistry\n",
    "\n",
    "## Table of content\n",
    "\n",
    "- Software\n",
    "- Supervised learning\n",
    "  - Common algorithms\n",
    "  - Model evaluation and data splitting\n",
    "  - Basic steps\n",
    "- Hands-on exercises\n",
    "  - Regression example\n",
    "\n",
    "\n",
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15d3c35",
   "metadata": {},
   "source": [
    "# 0. Software\n",
    "### Scikit-learn\n",
    "Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities. We will learn to use scikit-learn to do machine learning work. You can also browse the scikit-learn [user guide](https://scikit-learn.org/stable/user_guide.html) and [tutorials](https://scikit-learn.org/stable/tutorial/index.html) for additional details.\n",
    "### Essential Libraries and Tools \n",
    "Scikit-learn depends on two other Python packages, NumPy and SciPy. For plotting and interactive development, you should also install matplotlib, IPython, and the Jupyter Notebook.\n",
    "- **NumPy** is one of the fundamental packages for scientific computing in Python. In scikit-learn, the NumPy array is the fundamental data structure. Any data youâ€™re using will have to be converted to a NumPy array.\n",
    "- **SciPy** is a collection of functions for scientific computing in Python. Scikit-learn draws from SciPyâ€™s collection of functions for implementing its algorithms.\n",
    "- **Matplotlib** is the primary scientific plotting library in Python. It provides functions for making publication-quality visualizations such as line charts, histograms, scatter plots, and so on.\n",
    "- **Pandas** Python library for data wrangling and analysis. It can ingest from a great variety of file formats and databases, like SQL, Excel files, and comma-separated values (CSV) files.\n",
    "\n",
    "### XGBoost\n",
    "XGBoost (eXtreme Gradient Boosting) is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. You can also browse the [XGBoost Documentation](https://xgboost.readthedocs.io/en/stable/) for additional details.\n",
    "\n",
    "### DeepChem\n",
    "DeepChem is a high quality open-source toolchain that democratizes the use of deep-learning in chemistry, biology and materials science. It also provides various tools for dataset loader, splitters, molecular featurization, model construction and hyperparameter tuning. You can also browse the [DeepChem Ducumentation](https://deepchem.readthedocs.io/en/latest/) for additional details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fbf541",
   "metadata": {},
   "source": [
    "We will first install the required libraries. We also need `RDKit` library to process and analyze molecules, like calculating molecular descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4688b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy scipy matplotlib scikit-learn pandas rdkit xgboost deepchem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dba2fc2",
   "metadata": {},
   "source": [
    "# 1. Supervised learning\n",
    "Two major types of supervised machine learning problems:\n",
    "- **Classification** task is to predict a class label, which is a choice from a predefined list of possibilities.\n",
    "- **Regression** task is to predict a continuous number, or a floating-point number.\n",
    "\n",
    "## 1.1 Common algorithms\n",
    "- k-Nearest Neighbors (k-NN)\n",
    "- Linear Models\n",
    "- Support Vector Machines (SVM)\n",
    "- Decision Trees\n",
    "- Ensembles of Decision Trees\n",
    "  - Random forests\n",
    "  - Gradient boosting machines\n",
    "\n",
    "We can use `scikit-learn` to create ML models of different algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86793e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d36424",
   "metadata": {},
   "source": [
    "**Exercise**: Create a k-NN classifier using scikit-learn. [Tip](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f1caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE\n",
    "\n",
    "# import\n",
    "' your code '\n",
    "\n",
    "# create knn model\n",
    "knn_clf = ' your code '\n",
    "\n",
    "### END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3441adba",
   "metadata": {},
   "source": [
    "Next time, you can browse the scikit-learn [user guide](https://scikit-learn.org/stable/user_guide.html) to learn about supported algorithms and how to create the model you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be81ecfe",
   "metadata": {},
   "source": [
    "## 1.2 Model evaluation and data splitting\n",
    "### Why do we need to split dataset?\n",
    "We want models learn from data to predict on new data, but we cannot use the data we used to build the model to evaluate it. Hence, you need to separate your input data into `training`, `validation`, and `test` subsets to prevent your model from overfitting and to evaluate your model effectively. If you have more time, you can read this [article](https://towardsdatascience.com/how-to-split-data-into-three-sets-train-validation-and-test-and-why-e50d22d3e54c) for more details.\n",
    "### Evaluation metrics\n",
    "The metrics used to evaluate the ML models are very important. The choice of metrics to use influences how model performance is measured and compared. The main evaluation metrics for regression and classification tasks are illustrated below. If you have more time, you can read this [article](https://blog.knoldus.com/model-evaluation-metrics-for-machine-learning-algorithms/) for more details.\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"https://www.oreilly.com/api/v2/epubs/9781492073048/files/assets/mlbf_0407.png\" width=\"500\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a633f2c",
   "metadata": {},
   "source": [
    "## 1.3 Basic steps\n",
    "0. Define the task\n",
    "1. Prepare data & split data\n",
    "2. Choose the model\n",
    "3. Train the model\n",
    "4. Evaluate the model\n",
    "5. Use the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048efaf2",
   "metadata": {},
   "source": [
    "# 2. Hands-on exercises\n",
    "## 2.1 Regression example\n",
    "Below is a simple example to show basic steps of regression tasks. **Our goal** is to build a ML model that can learn from chemical structures (as encoded in SMILES strings) to predict **water solubility**. We will use ESOL dataset from [MoleculeNet](https://doi.org/10.1039/C7SC02664A) to train the models. This dataset contains structures and water solubility data for 1128 compounds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a8b2f1",
   "metadata": {},
   "source": [
    "Load dataset & show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load dataset from a CSV file\n",
    "esol_df = pd.read_csv('data/esol.csv')\n",
    "esol_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52e9894",
   "metadata": {},
   "source": [
    "The original dataset contains 2 columns, where the `smiles` column represents the SMILES strings of the solute molecules. The column `log solubility (mol/L)` represents the solubility of molecules in water, which is the predicted target of our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2950f29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NumPy arrays from DataFrame for the input and target\n",
    "smiles = esol_df['smiles'].values\n",
    "y = esol_df['log solubility (mol/L)'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343779ed",
   "metadata": {},
   "source": [
    "We need to convert the SMILES strings of molecules into numerical values that can be used as input to the ML models. We can calculate molecular descirptors from SMILES strings by some software like `RDKit`, `DeepChem` and [Mordred](https://github.com/mordred-descriptor/mordred). Here we use DeepChem [Featurizers](https://deepchem.readthedocs.io/en/latest/api_reference/featurizers.html) to compute molecular descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5961b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we use molecular descriptors from RDKit, like molecular weight, number of valence electrons, maximum and minimum partial charge, etc.\n",
    "from deepchem.feat import RDKitDescriptors\n",
    "featurizer = RDKitDescriptors()\n",
    "features = featurizer.featurize(smiles)\n",
    "print(\"Number of molecular descriptors:\", features.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9c63ba",
   "metadata": {},
   "source": [
    "**Exercise**: You can try to use [MACCSKeysFingerprint](https://deepchem.readthedocs.io/en/latest/api_reference/featurizers.html#maccskeysfingerprint) in DeepChem [Featurizers](https://deepchem.readthedocs.io/en/latest/api_reference/featurizers.html) to compute molecular descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f941ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE\n",
    "\n",
    "# import\n",
    "' your code '\n",
    "\n",
    "# create featurizer\n",
    "mf_featurizer = ' your code '\n",
    "\n",
    "# compute molecular descriptors\n",
    "mf_features = ' your code '\n",
    "\n",
    "# show results\n",
    "print(\"Number of molecular descriptors (MACCS Fingerprint):\", mf_features.shape[1])\n",
    "\n",
    "### END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07fca6d",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f23025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Min-Max Normalization of features\n",
    "fea_max = features.max(axis=0)\n",
    "fea_min = features.min(axis=0)\n",
    "fea_norm = (features - fea_min) / (fea_max - fea_min)\n",
    "\n",
    "# Check if normalized features contain invalid values\n",
    "contain_nan = (True in np.isnan(fea_norm))\n",
    "if contain_nan:\n",
    "    print('Our normalized features contain invalid values, please delete them before model training!')\n",
    "    fea_norm = fea_norm[:, ~np.isnan(fea_norm).any(axis=0)]\n",
    "    print('Dropping of columns containing invalid values has been completed.')\n",
    "else:\n",
    "    print('Our normalized features do not contain invalid values.')\n",
    "print(\"Shape of molecular descriptors after data preprocessing:\", fea_norm.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138076f4",
   "metadata": {},
   "source": [
    "Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8675b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = fea_norm\n",
    "# training data size : test data size = 0.8 : 0.2\n",
    "# fixed seed using the random_state parameter, so it always has the same split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d369a",
   "metadata": {},
   "source": [
    "Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b94772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest regressor, and the default criterion is mean squared error (MSE)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "ranf_reg = RandomForestRegressor(n_estimators=10, random_state=0)  # using 10 trees and seed=0\n",
    "\n",
    "# XGBoost regressor\n",
    "from xgboost import XGBRegressor\n",
    "bst_reg = XGBRegressor(n_estimators=10, random_state=0)  # using 10 trees and seed=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4b6e04",
   "metadata": {},
   "source": [
    "Train and evaluate the models\n",
    "- Mean Squared Error: $MSE$ = $\\frac{1}{n} \\Sigma_{i=1}^n({y}-\\hat{y})^2$\n",
    "- Root Mean Squared Error: $RMSE$ = $\\sqrt{MSE}$ = $\\sqrt{\\frac{1}{n} \\Sigma_{i=1}^n({y}-\\hat{y})^2}$\n",
    "\n",
    "We choose `RMSE` (lower is better) as the evaluation metric for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b21ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# for random forests\n",
    "ranf_reg.fit(X_train, y_train)  # train the model\n",
    "y_pred_train = ranf_reg.predict(X_train)\n",
    "y_pred_test = ranf_reg.predict(X_test)\n",
    "ranf_train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "ranf_test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "ranf_train_rmse = ranf_train_mse ** 0.5\n",
    "ranf_test_rmse = ranf_test_mse ** 0.5\n",
    "print('Random forests performance:')\n",
    "print('RMSE on train set: {:.3f}, and test set: {:.3f}.\\n'.format(ranf_train_rmse, ranf_test_rmse))\n",
    "\n",
    "# for XGBoost\n",
    "bst_reg.fit(X_train, y_train)  # train the model\n",
    "y_pred_train = bst_reg.predict(X_train)\n",
    "y_pred_test = bst_reg.predict(X_test)\n",
    "bst_train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "bst_test_mse = mean_squared_error(y_test, y_pred_test)\n",
    "bst_train_rmse = bst_train_mse ** 0.5\n",
    "bst_test_rmse = bst_test_mse ** 0.5\n",
    "print('XGBoost performance:')\n",
    "print('RMSE on train set: {:.3f}, and test set: {:.3f}.'.format(bst_train_rmse, bst_test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712c715f",
   "metadata": {},
   "source": [
    "The results show that the RMSE value of random forests on the test set is smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209edf19",
   "metadata": {},
   "source": [
    "**Exercise**: Try to train a SVM model and evaluate it. [Tip](https://scikit-learn.org/stable/modules/svm.html#regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7746533",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE\n",
    "\n",
    "# import\n",
    "' your code '\n",
    "\n",
    "# create a model\n",
    "svm_reg = ' your code '\n",
    "\n",
    "# train the model\n",
    "' your code '\n",
    "\n",
    "# evaluate the model\n",
    "' your code '\n",
    "svm_train_rmse = ' your code '\n",
    "svm_test_rmse = ' your code '\n",
    "\n",
    "# print results\n",
    "print('SVM performance:')\n",
    "print('RMSE on train set: {:.3f}, and test set: {:.3f}.'.format(svm_train_rmse, svm_test_rmse))\n",
    "\n",
    "### END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de3621",
   "metadata": {},
   "source": [
    "Perfect! Now you have mastered training and evaluating the model you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304d42f3",
   "metadata": {},
   "source": [
    "Cross-validation and hyperparamter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d749bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for n_estimators in [5, 10, 15, 20]:\n",
    "    for max_features in ['auto', 'sqrt', 'log2']:\n",
    "        # for each combination of parameters, train a random forest model\n",
    "        rf_gs = RandomForestRegressor(n_estimators=n_estimators, max_features=max_features, random_state=0)\n",
    "        # perform cross-validation\n",
    "        scores = cross_val_score(rf_gs, X_train, y_train, cv=3)\n",
    "        # compute mean cross-validation accuracy\n",
    "        score = np.mean(scores)\n",
    "        # if we got a lower MSE (better performance), store the score and parameters\n",
    "        if score > best_score or best_score == 0:\n",
    "            best_score = score\n",
    "            best_parameters = {'max_features': max_features, 'n_estimators': n_estimators}\n",
    "# re-train a model using best hyperparameters\n",
    "rf_gs = RandomForestRegressor(**best_parameters, random_state=0)\n",
    "rf_gs.fit(X_train, y_train)\n",
    "y_pred_test = rf_gs.predict(X_test)\n",
    "rf_gs_mse = mean_squared_error(y_test, y_pred_test)\n",
    "rf_gs_rmse = rf_gs_mse ** 0.5\n",
    "print('Best paramter: ', best_parameters)\n",
    "print('Random forests performance after hyperparamter optimization:')\n",
    "print('RMSE on test set: {:.3f}.\\n'.format(rf_gs_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26cfbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another method\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': [5, 10, 15, 20],\n",
    "              'max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestRegressor(random_state=0), param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# re-train a model using best hyperparameters\n",
    "rf_gs = RandomForestRegressor(**grid_search.best_params_, random_state=0)\n",
    "rf_gs.fit(X_train, y_train)\n",
    "y_pred_test = rf_gs.predict(X_test)\n",
    "rf_gs_mse = mean_squared_error(y_test, y_pred_test)\n",
    "rf_gs_rmse = rf_gs_mse ** 0.5\n",
    "print('Best paramter: ', grid_search.best_params_)\n",
    "print('Random forests performance after hyperparamter optimization:')\n",
    "print('RMSE on test set: {:.3f}.\\n'.format(rf_gs_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4224cf6",
   "metadata": {},
   "source": [
    "Now, we get a better random forest model (0.699 < 0.705)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5622c1-38ec-4e45-b6bb-2547a31408f6",
   "metadata": {},
   "source": [
    "# Introduction to traditional ML.\n",
    "\n",
    "## Supervised learning\n",
    "\n",
    "Training a model to take inputs X and return output y.\n",
    "\n",
    "As you have seen in class, for this type of learning, we have two variants:\n",
    "\n",
    "- Classification\n",
    "- Regression\n",
    "\n",
    "Linear regression is one example of suppervised learning for regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4369daf7-90c9-4b68-abb9-ac5d80330dd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Regression\n",
    "\n",
    "### TODO: Improve this introduction based on the ESOL paper, why is solub. prediction important?\n",
    "\n",
    "One problem in both academic and industrial chemistry is predicting solubility. For instance we might know that some molecule has good potential as a ligand for some relevant reaction, however when you synthesize it, you realize it's not soluble under your already optimized reaction conditions! ðŸ˜¥\n",
    "\n",
    "It would be extremely useful to know the solubility of my molecule, **before I even try to synthesize it**!\n",
    "\n",
    "---\n",
    "\n",
    "In this task we will try to solve this using supervised learning. In particular, we will train a regression model using the very convenient [scikit-learn](https://www.kaggle.com/competitions/MerckActivity/data) Python library, to predict solubility based on some molecular descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b43b84-aaf6-48cf-893f-3e42267846bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Let's start with loading the data, visualizing some molecules and their solubility\n",
    "# Let's also see some stats. e.g. size of dataset, distribution of solubility, etc.\n",
    "\n",
    "# TODO: Generate features\n",
    "# TODO do a train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcce8c9-6a29-424b-af64-ed669a5c0070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Let's give an introduction to scikit learn by doing a simple linear regression and see the results.\n",
    "# TODO Introduce sckit-learn, and use a RF model for this.\n",
    "import tempfile\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.neighbors import KNeighborsTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_regression\n",
    "cache_path = tempfile.gettempdir()  # we use a temporary folder here\n",
    "X, _ = make_regression(n_samples=50, n_features=25, random_state=0)\n",
    "estimator = make_pipeline(\n",
    "    KNeighborsTransformer(mode='distance'),\n",
    "    Isomap(n_components=3, metric='precomputed'),\n",
    "    memory=cache_path)\n",
    "X_embedded = estimator.fit_transform(X)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fbad9e-a85a-4e1d-a9fa-39aaa5b31bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Let's train another model (this can be an excercise)\n",
    "\n",
    "# EXERCISE: Implement random forest and and XGBoost models using scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b8ae8d-2a3d-4634-aeb6-3e52df6956fb",
   "metadata": {},
   "source": [
    "# As we see, there are many possible models we can use for this task. But which one is better?\n",
    "\n",
    "In addition, each model has a set of hyperparameters that we need to tune ourselves. How do we select them?\n",
    "\n",
    "This is an important part of machine learning! What we want to know is: What is the best combination of model + model hyperparameters for our task? \n",
    "As you've seen in the course, common strategies to evaluate and compare model's performance include:\n",
    "\n",
    "- Splitting dataset in train/validation/test.\n",
    "- Doing cross-validation for hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e76a7d2-8e3a-466d-9dad-f83681ede02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split data in train/valid/test\n",
    "\n",
    "# Retrain the models on the train set, and compare them using the validation set.\n",
    "\n",
    "# What model is the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f494286d-5d26-4aa7-9b55-13de0ce0446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Let's do cross-validation\n",
    "\n",
    "# Optimize the hyperparameters for XGBoost, and again compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9494e4-f0bb-441d-981b-65da64b96254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Finally, compare all models on the test set.\n",
    "# Explain that test set should never be seen by models.\n",
    "# This is all completely new data so we know how it would work in real life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1d4f4b-d19f-43ba-94f8-a6751a55ca66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6c0988-ae0f-4f19-8de6-d4d4925f493b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8866de4-74b2-4f8e-b619-ed8aace169c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86ba8f80-fd59-44f7-beb5-31387ec376d3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Classification\n",
    "\n",
    "We now turn our attention towards the other type of supervised learning: classification.\n",
    "\n",
    "Many questions in chemistry can be framed as a classification task: \n",
    "\n",
    "- Will this molecule act as a nucleophile or electrophile in my reaction?\n",
    "- What is the smell of this substance? (fruity, citrus, sweet, ...)\n",
    "\n",
    "But in this tutorial we will try to respond:\n",
    "\n",
    "<div>\n",
    "<img src=\"img/is_this_toxic.png\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## For this, we need data. [MoleculeNet](https://moleculenet.org/datasets-1) provides several datasets, and we'll work with `ClinTox` for prediction of toxicity.\n",
    "\n",
    "ClinTox is a dataset containing `qualitative data of drugs approved by the FDA and those that have failed clinical trials for toxicity reasons`.\n",
    "\n",
    "Let's see if one of our models can tell what molecules are toxic!\n",
    "\n",
    "This is super useful for instance in drug discovery, where we want to know if a molecule has potential as a drug, **even before we synthesize it**.\n",
    "\n",
    "The steps we follow are similar to those we saw for regression:\n",
    "\n",
    "1. Prepare & split data\n",
    "2. Choose a model\n",
    "3. Train the model\n",
    "4. Evaluate the model\n",
    "5. Use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd83e8dd-2277-42c6-b99a-2eec6b0e44f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load clintox data from the data directory and see what it contains\n",
    "df_toxicity = pd.read_csv(\"data/toxcast_data.csv\")\n",
    "df_toxicity.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d241778d-4b07-44cd-8713-c11c736f5e5c",
   "metadata": {},
   "source": [
    "This dataset contains the molecule SMILES, plus a lot of data coming from different [toxicity measurements](https://www.epa.gov/chemical-research/exploring-toxcast-data).\n",
    "\n",
    "We will stick to `TOX21_TR_LUC_GH3_Antagonist`, as is the one for which we have more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51abea66-40f1-4183-b79d-ccee003a17f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tox = df_toxicity.loc[:,[\"smiles\",\"TOX21_TR_LUC_GH3_Antagonist\"]].dropna()\n",
    "df_tox.columns = [\"smiles\", \"toxic\"]\n",
    "df_tox.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3cfd3d-5090-4a34-8fde-c7e6f157e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "# Visualize some of the molecules of this dataset\n",
    "n=6\n",
    "smiles = df_tox.smiles.sample(n).values\n",
    "legend = df_tox.toxic.sample(n).values\n",
    "molecs = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "\n",
    "Draw.MolsToGridImage(\n",
    "    molecs,\n",
    "    subImgSize=(600,300),\n",
    "    legends=[\"Toxic\" if i==1 else \"Non toxic\" for i in legend]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d934d7-2b65-436f-a02f-f7115c6c977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many toxic molecules are in the dataset?\n",
    "counts = df_tox[\"toxic\"].value_counts()\n",
    "\n",
    "print(f\"The dataset contains {counts.sum()} molecules; {counts.iloc[1]} of them are toxic.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7330eb2-1955-4f1d-92a6-7a094ad50333",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Now, we will calculate some molecular descriptors using the [mordred package](http://mordred-descriptor.github.io/documentation/master/descriptors.html).\n",
    "\n",
    "This can take a while (how much??), you can use this time to explore a bit the more than 1600 descriptors from mordred!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf18155-356f-4305-9727-1ebf3f6d90ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from deepchem.feat import MordredDescriptors\n",
    "\n",
    "featurizer = MordredDescriptors(ignore_3D=True)\n",
    "features = featurizer.featurize(\"CCC\")\n",
    "print(\"Number of molecular descriptors:\", features.shape[1])\n",
    "\n",
    "X_raw = df_tox.smiles.apply(lambda x: featurizer.featurize(x))\n",
    "y_raw = df_tox.toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07858825-ebb8-4e41-8f6f-0b9dafe5838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As you see from the warnings, mordred couldn't calculate features for a few molecules (but don't worry!)\n",
    "# Remove these molecules from the dataset\n",
    "import numpy as np\n",
    "\n",
    "# Featurizer should return array of size (1, number_of_features)\n",
    "missing = X_raw.apply(lambda x: x.shape == (1, features.shape[1]))\n",
    "\n",
    "print(f\"Dropping {(~missing).sum()} molecules that couldn't be featurized.\")\n",
    "X = X_raw[missing].values\n",
    "y = y_raw[missing].values\n",
    "\n",
    "X = np.concatenate(X)\n",
    "\n",
    "# Save\n",
    "np.save(\"data/features_tox.npy\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6dc3fc-87f0-4198-a637-bb602803c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"data/features_tox.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df19e380-eaf6-4f72-851c-ccb226f1611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge: Which molecules couldn't be featurized? Why?\n",
    "# Using code from above, visualize the faulty molecules.\n",
    "\n",
    "##################\n",
    "# Your code here #\n",
    "##################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4920f04b-5cb3-4057-bac5-e7ed8eca57dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data splitting.\n",
    "\n",
    "For this exercise, we will do a simple train/test split as we will not optimize hyperparameters. (Maybe bonus exercise here?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c46051-b3dc-4931-91ed-7904dcc1d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train data size : test data size = 0.8 : 0.2\n",
    "# fixed seed using the random_state parameter, so it always has the same split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    train_size=0.8,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print(f\"Train set size is {X_train.shape[0]} rows, test set size is {X_test.shape[0]} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5de382e-50de-4211-911a-08ed09bfb4a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model\n",
    "\n",
    "Let's train a Random Forest Classification from [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a09c804-41d8-40fb-985a-625e83640efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "rf_clf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13029e24-4b8c-45c5-9bd9-be41479dba50",
   "metadata": {},
   "source": [
    "### Exercise: You have already seen some cool classification algorithms in class.\n",
    "\n",
    "In this exercise, your task is to implement your 2 favorite algorithms using sklearn. \n",
    "\n",
    "Recommendations: \n",
    "\n",
    "- You can choose from [Logistic Regression](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), [Support Vector Machines](https://scikit-learn.org/stable/modules/svm.html#classification), [Gradient Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting), or any other from the [sklearn documentation](https://scikit-learn.org/stable/supervised_learning.html).\n",
    "- Give a different name to each model. For instance, our Random Forest model is `rf_clf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ec970-200c-4d22-bd40-e2e791faa004",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# Your code here #\n",
    "##################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf09c91-bdcc-450b-ac7e-0799111fb453",
   "metadata": {},
   "source": [
    "## After training these models, let's see which one worked best! \n",
    "\n",
    "For the evaluation of classification models, **we use different metrics** than evaluation of regression models. \\\n",
    "You can read more about each metric [here](https://scikit-learn.org/stable/modules/model_evaluation.html), but for this tutorial we will use [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score), [ROC-AUC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score), and [F1 Score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121851be-f4b9-4ac0-83e0-269ecff3de7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate our models \n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "# Exercise: Use your models to predict the toxicity of the molecules on the test set.\n",
    "\n",
    "##################\n",
    "# Your code here #\n",
    "##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67108633-40d3-4cae-b45d-6f5853254dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# Let's calculate accuracy_score for all our models\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Accuracy of Random Forest Classifier is {acc_rf:.3f}\")\n",
    "auc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "print(f\"ROC-AUC of Random Forest Classifier is {auc_rf:.3f}\")\n",
    "f1s_rf = f1_score(y_test, y_pred_rf)\n",
    "print(f\"F1 Score of Random Forest Classifier is {f1s_rf:.3f}\")\n",
    "\n",
    "# Exercise: Calculate the 3 metrics for every model you trained, and compare results\n",
    "\n",
    "##################\n",
    "# Your code here #\n",
    "##################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eae97b-af7f-4d3a-a834-48ed7a400587",
   "metadata": {},
   "source": [
    "---\n",
    "Find out what each metric is telling us. Should we trust such high accuracies? Why is accuracy so high compared to the other metrics?\n",
    "\n",
    "YOUR ANSWER:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71f8e9d-d0ef-40b4-945e-fa85507cb922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO let's also do confusion matrix\n",
    "from pycm import ConfusionMatrix\n",
    "\n",
    "cm = ConfusionMatrix(actual_vector=y_test, predict_vector=y_pred_rf)\n",
    "cm.relabel(mapping={0:\"Non Toxic\", 1:\"Toxic\"})\n",
    "cm.plot(number_label=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd1393d-e1cf-4ac2-a387-71fd83ec6b1a",
   "metadata": {},
   "source": [
    "### Some models, like Random Forest, are inherently interpretable, so we can easily see what features are important:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ca8ce8-6a53-4f72-af0c-6399a0a13c00",
   "metadata": {},
   "source": [
    "---\n",
    "What can we learn from these results? \\\n",
    "Go to [Mordred documentation](http://mordred-descriptor.github.io/documentation/master/descriptors.html) and find these features. What are they, and do they make any sense?\n",
    "\n",
    "### Discuss\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410c192a-ecbf-48f4-81fc-8d67fbefc7b4",
   "metadata": {},
   "source": [
    "# So after all what, is my molecule toxic or what? Let's see what our model says!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b927033-af33-4e0a-b561-5a89e839c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define molecule here\n",
    "molecule = \"O=C1N(C)C(C2=C(N=CN2C)N1C)=O\"\n",
    "mol = Chem.MolFromSmiles(molecule)\n",
    "\n",
    "# Calculate features\n",
    "X_my_mol = featurizer.featurize(molecule)\n",
    "\n",
    "# Get model prediction\n",
    "is_toxic = rf_clf.predict(X_my_mol)\n",
    "is_toxic = \"This molecule is toxic!\" if is_toxic else \"This is not toxic :)\"\n",
    "\n",
    "Draw.MolsToGridImage(\n",
    "    [mol],\n",
    "    subImgSize=(600,300),\n",
    "    legends=[is_toxic],\n",
    "    molsPerRow=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095f403e-d4e8-4272-8e50-0807c4a9b21a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Should I trust this though?: Interpretability and explainability.\n",
    "\n",
    "> Cool, our models know stuff, but we also want to know! \\\n",
    "> What do they look at when they predict toxicity? Is there a key feature?\n",
    "\n",
    "\\\n",
    "Model explainability is a critical component of machine learning that seeks to provide insights into how a model arrives at its predictions or decisions. In other words, it aims to make the \"black box\" of machine learning models more transparent, so that we can understand the factors that are driving the model's output.\n",
    "\n",
    "There are many different methods for achieving model explainability (more on this [here](https://www.kaggle.com/learn/machine-learning-explainability)). \\\n",
    "These techniques can help us identify which features or variables are most important in driving the model's output, and can provide insights into the model's decision-making process.\n",
    "\n",
    "### Let's explore ways of measuring feature importance, which will tell us what our models are looking out when making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e33561-72c1-4b3a-880c-93aa79825a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(rf_clf.feature_importances_, name=\"importance\")\n",
    "std = pd.Series(np.std([tree.feature_importances_ for tree in rf_clf.estimators_], axis=0), \n",
    "                name=\"std\")\n",
    "\n",
    "importances = pd.concat([importances, std], axis=1)\n",
    "importances = importances.sort_values(by=\"importance\", ascending=False).iloc[:20]\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "importances[\"importance\"].plot.bar(yerr=importances[\"std\"], ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081c462e-0a0b-477c-a7a8-06ae6c613389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO train another model (maybe XGBoost) and explain using SHAP\n",
    "# Already too much for 2 hours, but can be left to read more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494863e8-5d37-4e6a-b4df-672e0ba3781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f00582-e254-4f21-9b7f-31d4d5dfd5f7",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Extra stuff, dev."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bdd0b1-0584-4dbe-9dc4-7dd295e4042b",
   "metadata": {},
   "source": [
    "# Tasks for today: \n",
    "\n",
    "- scikit learn\n",
    "- classification\n",
    "- regression: [ESOL dataset](https://www.kaggle.com/competitions/MerckActivity/data)\n",
    "- XGBoost: [Merck kaggle challenge](https://www.kaggle.com/competitions/MerckActivity/data)\n",
    "- SHAP values + feature importance\n",
    "- Evaluation of ML models\n",
    "- Cross-validation: hyperparameter tuning\n",
    "- Train/valid/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e11eab-75b9-44c0-9323-ddc4727c16d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(\"data/toxcast_data.csv\")\n",
    "num_nans = (~d.isna()).sum(axis=0).sort_values(ascending=False)\n",
    "d.iloc[:,1:].apply(lambda x: x.value_counts(dropna=False)).T.loc[num_nans.index[1:]].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1493a7f2-a544-4948-8e7f-4dfa1efd353f",
   "metadata": {},
   "source": [
    "# We'll play with balanced datasets. \n",
    "\n",
    "- TOX21_Aromatase_Inhibition \t6674 \t1276\n",
    "- TOX21_ERa_LUC_BG1_Agonist \t6691 \t1259\n",
    "- TOX21_TR_LUC_GH3_Antagonist \t6186 \t1764"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f306533-3f3e-485b-93c8-8daa1bda0e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1b1e114f4dae097b9e32029c5d22d73dc21a5dd723446d46774bd2adced9390"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
